{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62d17de-32d5-4339-8938-96ac85648255",
   "metadata": {},
   "source": [
    "# SpanMarker cross-validation training\n",
    "This notebook performs 5-fold crossvalidation for a SpanMarker model. Parquet files must be stored in the same directory. An internet connection is required to download the germeval2014 dataset necessary for feature mapping.\n",
    "\n",
    "The evaluation is performed separately in `cv_model_evaluation.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from customized_spanmarker_training import NoTrainPreprocTrainer, preprocess_dataset\n",
    "from datasets import Dataset, DatasetDict, concatenate_datasets, load_dataset\n",
    "from sklearn.model_selection import KFold\n",
    "from span_marker import SpanMarkerModel\n",
    "from span_marker.label_normalizer import AutoLabelNormalizer\n",
    "from torch.optim import AdamW\n",
    "from transformers import TrainingArguments, get_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211fd332-8d4c-4e43-a1ba-11a0a91ddd7b",
   "metadata": {},
   "source": [
    "Loading datasets remotely and from parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68be7db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/datasets_modules/datasets/gwlms--germeval2014/66c688527595f251c65f33876dfb2dee0ae258c4f5df3a6e908f3511559bf4c3 (last modified on Fri Jan  5 13:59:07 2024) since it couldn't be found locally at gwlms/germeval2014, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "germeval = load_dataset(\"gwlms/germeval2014\")[\"train\"]\n",
    "germeval = germeval.select_columns([\"tokens\", \"ner_tags\"])\n",
    "krp_19jhd = Dataset.from_parquet(\"krp_19jhd.parquet\")\n",
    "krp_20jhd = Dataset.from_parquet(\"krp_20jhd.parquet\")\n",
    "rrb_19jhd = Dataset.from_parquet(\"rrb_19jhd.parquet\")\n",
    "rrb_20jhd = Dataset.from_parquet(\"rrb_20jhd.parquet\")\n",
    "gszh = Dataset.from_parquet(\"gszh.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35243699-58f9-411c-a148-d61df774c8fc",
   "metadata": {},
   "source": [
    "Mapping features to the original germeval2014 indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf826ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "krp_19jhd = krp_19jhd.map(features=germeval.features)\n",
    "krp_20jhd = krp_20jhd.map(features=germeval.features)\n",
    "rrb_19jhd = rrb_19jhd.map(features=germeval.features)\n",
    "rrb_20jhd = rrb_20jhd.map(features=germeval.features)\n",
    "gszh = gszh.map(features=germeval.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8d3f1-7f8d-4208-8b38-09d90db76326",
   "metadata": {},
   "source": [
    "Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3deebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianvanderlek/anaconda3/envs/ner2/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13090' max='13090' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13090/13090 13:30:23, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.907415</td>\n",
       "      <td>0.941786</td>\n",
       "      <td>0.924281</td>\n",
       "      <td>0.989128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.927280</td>\n",
       "      <td>0.940590</td>\n",
       "      <td>0.933888</td>\n",
       "      <td>0.991111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.925623</td>\n",
       "      <td>0.947767</td>\n",
       "      <td>0.936564</td>\n",
       "      <td>0.991401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.004906</td>\n",
       "      <td>0.923821</td>\n",
       "      <td>0.952552</td>\n",
       "      <td>0.937966</td>\n",
       "      <td>0.991668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.930051</td>\n",
       "      <td>0.948963</td>\n",
       "      <td>0.939412</td>\n",
       "      <td>0.991802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.923997</td>\n",
       "      <td>0.954944</td>\n",
       "      <td>0.939216</td>\n",
       "      <td>0.991802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.926299</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>0.939048</td>\n",
       "      <td>0.991935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.926659</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>0.939233</td>\n",
       "      <td>0.991935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8b919c95ef42f8860db53ace817f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label normalizing the evaluation dataset:   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07133d9700e487eb95db0a6b3a7992f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8107a9b660884074a08904f8363b02d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b661a99ef9a9451ba73574cd53e7705d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the evaluation dataset:   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model won't be able to predict 7.828004% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words and the maximum model input length of 256 tokens.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 2721 total entities:\n",
      "- 4 missed entities with 9 words (0.147005%)\n",
      "- 1 missed entities with 10 words (0.036751%)\n",
      "Additionally, a total of 208 (7.644248%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e4c6cdf1c8416ba397ffd05142eea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60c273e1f784ab7b8d216c5c24fad5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the evaluation dataset:   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model won't be able to predict 7.828004% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words and the maximum model input length of 256 tokens.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 2721 total entities:\n",
      "- 4 missed entities with 9 words (0.147005%)\n",
      "- 1 missed entities with 10 words (0.036751%)\n",
      "Additionally, a total of 208 (7.644248%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2169b4a8f56c4b598a4dd3c4a8be6133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef486e5aa9f43d4915f166d0fd15e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label normalizing the train dataset:   0%|          | 0/6515 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690bfa3ebd6c4005849ab5d07e7ebcc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the train dataset:   0%|          | 0/6515 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model will ignore 4.319035% of all annotated entities in the train dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words and the maximum model input length of 256 tokens.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 10118 total entities:\n",
      "- 4 missed entities with 9 words (0.039534%)\n",
      "- 1 missed entities with 10 words (0.009883%)\n",
      "- 1 missed entities with 13 words (0.009883%)\n",
      "Additionally, a total of 431 (4.259735%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138a7f56a25142deb077ae15124ec6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/6515 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13290' max='13290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13290/13290 5:09:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.919292</td>\n",
       "      <td>0.942895</td>\n",
       "      <td>0.930944</td>\n",
       "      <td>0.990336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.934085</td>\n",
       "      <td>0.953519</td>\n",
       "      <td>0.943702</td>\n",
       "      <td>0.992221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.956175</td>\n",
       "      <td>0.946746</td>\n",
       "      <td>0.992555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.938971</td>\n",
       "      <td>0.953519</td>\n",
       "      <td>0.946189</td>\n",
       "      <td>0.992603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.937121</td>\n",
       "      <td>0.956618</td>\n",
       "      <td>0.946769</td>\n",
       "      <td>0.992794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.941228</td>\n",
       "      <td>0.957061</td>\n",
       "      <td>0.949078</td>\n",
       "      <td>0.993176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.941815</td>\n",
       "      <td>0.960159</td>\n",
       "      <td>0.950899</td>\n",
       "      <td>0.993128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.942048</td>\n",
       "      <td>0.957061</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.993128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9b104051a64a818703a9561f1aea6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label normalizing the evaluation dataset:   0%|          | 0/1629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd6c272d8304fa9b44cbc70ed40f578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bccebaae83a49b4b9796ca7ac40a1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffaf14ea5314f58b00628f500c41025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the evaluation dataset:   0%|          | 0/1629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model won't be able to predict 1.267483% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words and the maximum model input length of 256 tokens.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 2288 total entities:\n",
      "- 1 missed entities with 9 words (0.043706%)\n",
      "Additionally, a total of 28 (1.223776%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7341fc476743f5b47a2db269fce71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/1629 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5d528cdd3a4995998be81c0b81b48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label normalizing the train dataset:   0%|          | 0/6516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1ab9c9f95c492fb785219dd0822824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the train dataset:   0%|          | 0/6516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model will ignore 4.157372% of all annotated entities in the train dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words and the maximum model input length of 256 tokens.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 9862 total entities:\n",
      "- 5 missed entities with 9 words (0.050700%)\n",
      "- 1 missed entities with 10 words (0.010140%)\n",
      "- 1 missed entities with 13 words (0.010140%)\n",
      "Additionally, a total of 403 (4.086392%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69355b872439419886355998c88db8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/6516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13100' max='13100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13100/13100 5:06:02, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.003916</td>\n",
       "      <td>0.912301</td>\n",
       "      <td>0.944936</td>\n",
       "      <td>0.928332</td>\n",
       "      <td>0.989736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.926916</td>\n",
       "      <td>0.948151</td>\n",
       "      <td>0.937413</td>\n",
       "      <td>0.991526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.929329</td>\n",
       "      <td>0.951367</td>\n",
       "      <td>0.940218</td>\n",
       "      <td>0.991616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.941295</td>\n",
       "      <td>0.940916</td>\n",
       "      <td>0.941106</td>\n",
       "      <td>0.991979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.936356</td>\n",
       "      <td>0.946141</td>\n",
       "      <td>0.941224</td>\n",
       "      <td>0.991820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.932250</td>\n",
       "      <td>0.945740</td>\n",
       "      <td>0.938947</td>\n",
       "      <td>0.991412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.932411</td>\n",
       "      <td>0.948151</td>\n",
       "      <td>0.940215</td>\n",
       "      <td>0.991865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.937873</td>\n",
       "      <td>0.946543</td>\n",
       "      <td>0.942188</td>\n",
       "      <td>0.992069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5875b0042c7479e965239b7850a7228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label normalizing the evaluation dataset:   0%|          | 0/1628 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9685e6972e6042c0a7d6ed6673832466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb48ca4765a41ff88280b4b44c89b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c45533f964a42b5a8bd2cdbff895b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the evaluation dataset:   0%|          | 0/1628 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model won't be able to predict 2.201258% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum model input length of 256 tokens.\n",
      "A total of 56 (2.201258%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cce16e717644ce91093728e91e2a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/1628 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d315c298846445beae7319380e4c9a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label normalizing the train dataset:   0%|          | 0/6516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f8e365cfba4c57bcfad046e3c32151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the train dataset:   0%|          | 0/6516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model will ignore 4.343945% of all annotated entities in the train dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words and the maximum model input length of 256 tokens.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 10083 total entities:\n",
      "- 5 missed entities with 9 words (0.049588%)\n",
      "- 1 missed entities with 10 words (0.009918%)\n",
      "Additionally, a total of 432 (4.284439%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b83fbff3074e7fbb33972d255d04fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/6516 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13200' max='13200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13200/13200 5:07:03, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.898425</td>\n",
       "      <td>0.944227</td>\n",
       "      <td>0.920756</td>\n",
       "      <td>0.989814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.913498</td>\n",
       "      <td>0.952505</td>\n",
       "      <td>0.932594</td>\n",
       "      <td>0.991203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.921186</td>\n",
       "      <td>0.947277</td>\n",
       "      <td>0.934049</td>\n",
       "      <td>0.991527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.922204</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.938583</td>\n",
       "      <td>0.992129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>0.922040</td>\n",
       "      <td>0.953377</td>\n",
       "      <td>0.937446</td>\n",
       "      <td>0.992106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.920320</td>\n",
       "      <td>0.951198</td>\n",
       "      <td>0.935505</td>\n",
       "      <td>0.991851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>0.920775</td>\n",
       "      <td>0.952070</td>\n",
       "      <td>0.936161</td>\n",
       "      <td>0.991990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>0.921486</td>\n",
       "      <td>0.951198</td>\n",
       "      <td>0.936106</td>\n",
       "      <td>0.991898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fcc4a1009347379bcee8808fa6e2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label normalizing the evaluation dataset:   0%|          | 0/1628 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f63fd110064c57b4c80fc768f8b887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98701fb6d6194d52bb91fe7ac8ea8d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e261bbd697ff484288bd15ed11726220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the evaluation dataset:   0%|          | 0/1628 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model won't be able to predict 1.205338% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words and the maximum model input length of 256 tokens.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 2323 total entities:\n",
      "- 1 missed entities with 13 words (0.043048%)\n",
      "Additionally, a total of 27 (1.162290%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3284093c571487ea603cdc61c1feae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/1628 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e191d6d4cfba48cca171e0abb00a7b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label normalizing the train dataset:   0%|          | 0/6517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f561532c90104d829bfcb010603ec6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the train dataset:   0%|          | 0/6517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model will ignore 3.300932% of all annotated entities in the train dataset. This is caused by the SpanMarkerModel maximum entity length of 8 words and the maximum model input length of 256 tokens.\n",
      "These are the frequencies of the missed entities due to maximum entity length out of 9876 total entities:\n",
      "- 5 missed entities with 9 words (0.050628%)\n",
      "- 1 missed entities with 10 words (0.010126%)\n",
      "- 1 missed entities with 13 words (0.010126%)\n",
      "Additionally, a total of 319 (3.230053%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ca3478bf1248aa81fb4ff5d612800b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/6517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13140' max='13140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13140/13140 5:06:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.906837</td>\n",
       "      <td>0.948954</td>\n",
       "      <td>0.927418</td>\n",
       "      <td>0.990738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>0.929947</td>\n",
       "      <td>0.949791</td>\n",
       "      <td>0.939764</td>\n",
       "      <td>0.991942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.933498</td>\n",
       "      <td>0.951464</td>\n",
       "      <td>0.942395</td>\n",
       "      <td>0.992191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.929301</td>\n",
       "      <td>0.951464</td>\n",
       "      <td>0.940252</td>\n",
       "      <td>0.992214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.946128</td>\n",
       "      <td>0.940586</td>\n",
       "      <td>0.943349</td>\n",
       "      <td>0.992509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.941152</td>\n",
       "      <td>0.950209</td>\n",
       "      <td>0.945659</td>\n",
       "      <td>0.992986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.938246</td>\n",
       "      <td>0.953556</td>\n",
       "      <td>0.945839</td>\n",
       "      <td>0.993031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.945394</td>\n",
       "      <td>0.948954</td>\n",
       "      <td>0.947171</td>\n",
       "      <td>0.993167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b3e0233a494683ac54230856178c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label normalizing the evaluation dataset:   0%|          | 0/1627 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e44bf6d69d424a921e7c69fcf7c808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e9b20181c449abbb1ab851c90598b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4157882bd14540cdb6ca8529e40550f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing the evaluation dataset:   0%|          | 0/1627 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This SpanMarker model won't be able to predict 5.533597% of all annotated entities in the evaluation dataset. This is caused by the SpanMarkerModel maximum model input length of 256 tokens.\n",
      "A total of 140 (5.533597%) entities were missed due to the maximum input length.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ccaa6866d8d47aa833c3d3a1121fede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Spreading data between multiple samples:   0%|          | 0/1627 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n",
      "Using the latest cached version of the module from /Users/adrianvanderlek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c (last modified on Fri Jan  5 15:34:57 2024) since it couldn't be found locally at evaluate-metric--seqeval, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "# Overarching training parameters\n",
    "gradient_accumulation_steps = 2\n",
    "train_batch_size = 4\n",
    "n_epochs = 10\n",
    "\n",
    "# Cross-validation with custom stratified KFold over all five datasets\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for i, (\n",
    "    (krp_19jhd_train_idx, krp_19jhd_eval_idx),\n",
    "    (krp_20jhd_train_idx, krp_20jhd_eval_idx),\n",
    "    (rrb_19jhd_train_idx, rrb_19jhd_eval_idx),\n",
    "    (rrb_20jhd_train_idx, rrb_20jhd_eval_idx),\n",
    "    (gszh_train_idx, gszh_eval_idx),\n",
    ") in enumerate(\n",
    "    list(\n",
    "        zip(\n",
    "            kf.split(np.zeros(krp_19jhd.num_rows)),\n",
    "            kf.split(np.zeros(krp_20jhd.num_rows)),\n",
    "            kf.split(np.zeros(rrb_19jhd.num_rows)),\n",
    "            kf.split(np.zeros(rrb_20jhd.num_rows)),\n",
    "            kf.split(np.zeros(gszh.num_rows)),\n",
    "        )\n",
    "    )\n",
    "):\n",
    "    print(f\"Fold {i}:\")\n",
    "\n",
    "    # Selecting the training subfolds\n",
    "    krp_19jhd_train = krp_19jhd.select(krp_19jhd_train_idx)\n",
    "    krp_20jhd_train = krp_20jhd.select(krp_20jhd_train_idx)\n",
    "    rrb_19jhd_train = rrb_19jhd.select(rrb_19jhd_train_idx)\n",
    "    rrb_20jhd_train = rrb_20jhd.select(rrb_20jhd_train_idx)\n",
    "    gszh_train = gszh.select(gszh_train_idx)\n",
    "\n",
    "    # Selecting the test subfolds\n",
    "    krp_19jhd_eval = krp_19jhd.select(krp_19jhd_eval_idx)\n",
    "    krp_20jhd_eval = krp_20jhd.select(krp_20jhd_eval_idx)\n",
    "    rrb_19jhd_eval = rrb_19jhd.select(rrb_19jhd_eval_idx)\n",
    "    rrb_20jhd_eval = rrb_20jhd.select(rrb_20jhd_eval_idx)\n",
    "    gszh_eval = gszh.select(gszh_eval_idx)\n",
    "\n",
    "    # Concatenating training subfolds\n",
    "    train_fold = concatenate_datasets(\n",
    "        [krp_19jhd_train, krp_20jhd_train, rrb_19jhd_train, rrb_20jhd_train, gszh_train]\n",
    "    ).shuffle(\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    # Concatenating test subfolds\n",
    "    eval_fold = concatenate_datasets(\n",
    "        [krp_19jhd_eval, krp_20jhd_eval, rrb_19jhd_eval, rrb_20jhd_eval, gszh_eval]\n",
    "    )\n",
    "\n",
    "    # Creating fold dataset\n",
    "    fold_dataset = DatasetDict(\n",
    "        {\n",
    "            \"train\": train_fold,\n",
    "            \"eval\": eval_fold,\n",
    "            \"eval_krp_19jhd\": krp_19jhd_eval,\n",
    "            \"eval_krp_20jhd\": krp_20jhd_eval,\n",
    "            \"eval_rrb_19jhd\": rrb_19jhd_eval,\n",
    "            \"eval_rrb_20jhd\": rrb_20jhd_eval,\n",
    "            \"eval_gszh\": gszh_eval,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Model instantiation\n",
    "    encoder_id = \"stefan-it/span-marker-gelectra-large-germeval14\"\n",
    "    model = SpanMarkerModel.from_pretrained(\n",
    "        # Required arguments\n",
    "        encoder_id,\n",
    "        # Optional arguments\n",
    "        model_max_length=256,\n",
    "        entity_max_length=8,\n",
    "    )\n",
    "\n",
    "    # Training arguments\n",
    "    args = TrainingArguments(\n",
    "        output_dir=\"models/span-marker-ktzh-stazh-cv/tmp\",\n",
    "        learning_rate=1e-05,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        per_device_train_batch_size=train_batch_size,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=n_epochs,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"no\",\n",
    "        eval_steps=1500,\n",
    "        push_to_hub=False,\n",
    "        logging_steps=50,\n",
    "        warmup_ratio=0.05,\n",
    "    )\n",
    "\n",
    "    # Preprocessing dataset\n",
    "    train_dataset = preprocess_dataset(\n",
    "        model,\n",
    "        fold_dataset[\"train\"],\n",
    "        AutoLabelNormalizer.from_config(model.config),\n",
    "        model.tokenizer,\n",
    "        dataset_name=\"train\",\n",
    "        is_evaluate=False,\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Setting up learning rate scheduler\n",
    "    num_training_steps = int(\n",
    "        len(train_dataset) / gradient_accumulation_steps / train_batch_size * n_epochs\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-05)\n",
    "\n",
    "    l_r_scheduler = get_scheduler(\n",
    "        \"polynomial\",\n",
    "        optimizer,\n",
    "        num_warmup_steps=int(0.05 * num_training_steps),\n",
    "        num_training_steps=num_training_steps,\n",
    "        scheduler_specific_kwargs=dict(lr_end=5e-07, power=3),\n",
    "    )\n",
    "\n",
    "    # Instantiating trainer\n",
    "    trainer = NoTrainPreprocTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=fold_dataset[\"eval\"],\n",
    "        optimizers=(optimizer, l_r_scheduler),\n",
    "    )\n",
    "\n",
    "    # Training and saving separate model per fold\n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"models/span-marker-ktzh-stazh-cv/fold_{i}\")\n",
    "\n",
    "    del trainer\n",
    "    del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
